import os
import openai
import logging
import asyncio
from aiogram import Bot, Dispatcher, types
from aiogram.filters import CommandStart
from aiogram.types import Message
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env
load_dotenv()
logging.basicConfig(level=logging.INFO)

# –ü—Ä–∞–≤–∏–ª—å–Ω–æ –ø–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω—ã
TELEGRAM_BOT_TOKEN = os.getenv("8025483084:AAH_CgKKebA0UUi_mKEKzk82YenNSQ2Li4M")
OPENAI_API_KEY = os.getenv("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")


# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–ª—é—á OpenAI
openai.api_key = OPENAI_API_KEY

# –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä—ã –±–æ—Ç–∞ –∏ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞
bot = Bot(token=TELEGRAM_BOT_TOKEN)
dp = Dispatcher()

# –§—É–Ω–∫—Ü–∏—è –æ–±—â–µ–Ω–∏—è —Å GPT
async def get_gpt_reply(user_message: str) -> str:
    try:
        response = await openai.ChatCompletion.acreate(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "–¢—ã –≤–µ—Å—ë–ª—ã–π –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –∏–º–µ–Ω–∏ –ü–∞–π–º–æ–Ω."},
                {"role": "user", "content": user_message},
            ]
        )
        return response.choices[0].message["content"].strip()
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ GPT: {e}"

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã /start
@dp.message(CommandStart())
async def start(message: Message):
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –Ø –ü–∞–π–º–æ–Ω, —Ç–≤–æ–π –Ω–∞–ø–∞—Ä–Ω–∏–∫! üéâ –ù–∞–ø–∏—à–∏ –º–Ω–µ —á—Ç–æ-–Ω–∏–±—É–¥—å!")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±—ã—á–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
@dp.message()
async def chat(message: Message):
    await message.answer("‚åõ –î—É–º–∞—é...")
    reply = await get_gpt_reply(message.text)
    await message.answer(reply)

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
