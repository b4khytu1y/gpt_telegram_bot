import os
import openai
import logging
import asyncio
from aiogram import Bot, Dispatcher, types
from aiogram.filters import CommandStart
from aiogram.types import Message
from dotenv import load_dotenv

load_dotenv()
logging.basicConfig(level=logging.INFO)

TELEGRAM_BOT_TOKEN = os.getenv("8025483084:AAH_CgKKebA0UUi_mKEKzk82YenNSQ2Li4M")
OPENAI_API_KEY = os.getenv("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")

openai.api_key = OPENAI_API_KEY
bot = Bot(token=TELEGRAM_BOT_TOKEN)
dp = Dispatcher()


async def get_gpt_reply(user_message: str) -> str:
    try:
        response = await openai.ChatCompletion.acreate(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "–¢—ã –≤–µ—Å—ë–ª—ã–π –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –∏–º–µ–Ω–∏ –ü–∞–π–º–æ–Ω."},
                {"role": "user", "content": user_message},
            ]
        )
        return response.choices[0].message["content"].strip()
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ GPT: {e}"


@dp.message(CommandStart())
async def start(message: Message):
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –Ø –ü–∞–π–º–æ–Ω, —Ç–≤–æ–π –Ω–∞–ø–∞—Ä–Ω–∏–∫! üéâ –ù–∞–ø–∏—à–∏ –º–Ω–µ —á—Ç–æ-–Ω–∏–±—É–¥—å!")


@dp.message()
async def chat(message: Message):
    await message.answer("‚åõ –î—É–º–∞—é...")
    reply = await get_gpt_reply(message.text)
    await message.answer(reply)


async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
